name: Performance Monitoring & Optimization

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run performance tests daily at 2 AM UTC
    - cron: '0 2 * * *'

permissions:
  contents: read
  pull-requests: write
  actions: read

env:
  NODE_VERSION: '20'
  JAVA_VERSION: '21'

jobs:
  frontend-performance:
    name: Frontend Performance Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Install dependencies
      working-directory: ./frontend
      run: npm ci

    - name: Build frontend
      working-directory: ./frontend
      run: npm run build

    - name: Analyze bundle size
      working-directory: ./frontend
      run: npm run analyze:bundle > bundle-analysis.txt

    - name: Check bundle size limits
      working-directory: ./frontend
      run: |
        # Extract bundle sizes and check against limits
        TOTAL_SIZE=$(du -sb dist/ | cut -f1)
        GZIPPED_SIZE=$(find dist/ -name "*.js" -exec gzip -c {} \; | wc -c)

        echo "Total bundle size: $TOTAL_SIZE bytes"
        echo "Estimated gzipped size: $GZIPPED_SIZE bytes"

        # Fail if bundle is too large (3MB total, 800KB gzipped)
        if [ $TOTAL_SIZE -gt 3145728 ]; then
          echo "❌ Bundle size too large: $TOTAL_SIZE bytes > 3MB"
          exit 1
        fi

        if [ $GZIPPED_SIZE -gt 819200 ]; then
          echo "❌ Gzipped bundle too large: $GZIPPED_SIZE bytes > 800KB"
          exit 1
        fi

        echo "✅ Bundle size within limits"

    - name: Install Playwright
      working-directory: ./frontend
      run: npx playwright install --with-deps

    - name: Run performance tests
      working-directory: ./frontend
      run: npm run test:e2e -- tests/e2e/performance/
      env:
        CI: true

    - name: Generate Lighthouse reports
      working-directory: ./frontend
      run: |
        npm install -g @lhci/cli lighthouse
        npm run build
        npm run preview &
        PREVIEW_PID=$!
        sleep 10

        # Wait for preview server to be ready
        for i in {1..30}; do
          if curl -f http://localhost:4173 > /dev/null 2>&1; then
            echo "Preview server is ready"
            break
          fi
          echo "Waiting for preview server... ($i/30)"
          sleep 2
        done

        # Run Lighthouse with headless Chrome flags
        lhci collect \
          --url=http://localhost:4173 \
          --numberOfRuns=3 \
          --settings.chromeFlags="--headless --no-sandbox --disable-gpu --disable-dev-shm-usage" \
          || echo "Lighthouse collection failed, continuing anyway"

        # Kill preview server
        kill $PREVIEW_PID || true

        # Upload results (don't fail if upload fails)
        lhci upload || true

    - name: Upload performance artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: frontend-performance-results
        path: |
          frontend/bundle-analysis.txt
          frontend/test-results/
          frontend/.lighthouseci/
        retention-days: 30

  backend-performance:
    name: Backend Performance Testing
    runs-on: ubuntu-latest
    timeout-minutes: 45

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Java
      uses: actions/setup-java@v4
      with:
        java-version: ${{ env.JAVA_VERSION }}
        distribution: 'temurin'

    - name: Cache Gradle dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.gradle/caches
          ~/.gradle/wrapper
        key: gradle-${{ runner.os }}-${{ hashFiles('**/*.gradle*', '**/gradle-wrapper.properties') }}
        restore-keys: |
          gradle-${{ runner.os }}-

    - name: Run backend build
      working-directory: ./backend
      run: ./gradlew build -x test

    - name: Run performance-focused tests
      working-directory: ./backend
      run: |
        ./gradlew test --tests "*PerformanceTest" \
                      --tests "*IntegrationTest" \
                      --tests "*LoadTest" \
                      -Dspring.profiles.active=performance
      env:
        SPRING_DATASOURCE_URL: jdbc:postgresql://localhost:5432/testdb
        SPRING_DATASOURCE_USERNAME: testuser
        SPRING_DATASOURCE_PASSWORD: testpass
        SPRING_REDIS_HOST: localhost
        SPRING_REDIS_PORT: 6379

    - name: Run database query analysis
      working-directory: ./backend
      run: |
        ./gradlew bootRun --args='--spring.profiles.active=performance --analyze-queries=true' &
        APP_PID=$!
        sleep 30

        # Run query analysis script
        curl -f http://localhost:8080/actuator/health || true
        curl -f http://localhost:8080/api/v1/performance/metrics || true

        kill $APP_PID || true

    - name: Generate JVM performance report
      working-directory: ./backend
      run: |
        ./gradlew test --tests "*PerformanceTest" \
                      -Djvm.args="-XX:+PrintGCDetails -XX:+PrintGCTimeStamps" \
                      > jvm-performance.log 2>&1 || true

    - name: Upload backend performance artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: backend-performance-results
        path: |
          backend/build/reports/
          backend/jvm-performance.log
        retention-days: 30

  database-performance:
    name: Database Performance Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 20

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup database schema
      run: |
        PGPASSWORD=testpass psql -h localhost -U testuser -d testdb -f backend/src/main/resources/db/migration/V001__Initial_schema.sql || true
        PGPASSWORD=testpass psql -h localhost -U testuser -d testdb -f backend/src/main/resources/db/migration/V010__add_performance_indexes.sql || true
        PGPASSWORD=testpass psql -h localhost -U testuser -d testdb -f backend/src/main/resources/db/migration/V022__create_user_module_tables.sql || true

    - name: Run database performance tests
      run: |
        # Create test data
        echo "Creating test data..." > query-performance.log
        PGPASSWORD=testpass psql -h localhost -U testuser -d testdb -c "
        INSERT INTO organizations (id, name, slug, created_at, updated_at)
        SELECT gen_random_uuid(), 'Org ' || i, 'org-' || i, NOW(), NOW()
        FROM generate_series(1, 1000) i;
        "

        PGPASSWORD=testpass psql -h localhost -U testuser -d testdb -c "
        INSERT INTO audit_events (id, organization_id, event_type, severity, description, timestamp, created_at)
        SELECT gen_random_uuid(),
               (SELECT id FROM organizations ORDER BY RANDOM() LIMIT 1),
               (ARRAY['LOGIN', 'LOGOUT', 'CREATE', 'UPDATE', 'DELETE'])[ceil(random()*5)],
               'INFO',
               'Test audit event',
               NOW() - (random() * interval '30 days'),
               NOW()
        FROM generate_series(1, 10000);
        "

        # Test query performance
        echo "" >> query-performance.log
        echo "Testing query performance..." >> query-performance.log
        PGPASSWORD=testpass psql -h localhost -U testuser -d testdb -c "
        EXPLAIN (ANALYZE, BUFFERS)
        SELECT COUNT(*) FROM audit_events
        WHERE organization_id = (SELECT id FROM organizations LIMIT 1)
        AND timestamp >= NOW() - interval '7 days';
        " >> query-performance.log

    - name: Upload database performance results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: database-performance-results
        path: query-performance.log
        retention-days: 30

  performance-report:
    name: Generate Performance Report
    runs-on: ubuntu-latest
    needs: [frontend-performance, backend-performance, database-performance]
    if: always()

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Download all artifacts
      uses: actions/download-artifact@v4

    - name: Generate comprehensive report
      run: |
        cat > performance-report.md << 'EOF'
        # Performance Analysis Report

        **Date:** $(date)
        **Commit:** ${{ github.sha }}
        **Branch:** ${{ github.ref_name }}

        ## Summary

        ### Frontend Performance
        - Bundle size analysis completed
        - Lighthouse performance tests executed
        - Core Web Vitals measured

        ### Backend Performance
        - API response time analysis completed
        - JVM performance metrics collected
        - Database query performance analyzed

        ### Database Performance
        - Query execution plans analyzed
        - Index usage verified
        - Slow query detection completed

        ## Recommendations

        Based on the performance analysis, consider the following optimizations:

        1. **Frontend:**
           - Monitor bundle size growth
           - Optimize lazy loading implementation
           - Review Core Web Vitals thresholds

        2. **Backend:**
           - Review slow database queries
           - Optimize JVM garbage collection
           - Consider caching strategy improvements

        3. **Database:**
           - Verify index usage on high-traffic queries
           - Monitor connection pool sizing
           - Consider query optimization opportunities

        ## Artifacts

        Performance test artifacts are available for 30 days:
        - Frontend performance results
        - Backend performance results
        - Database performance results

        EOF

    - name: Upload performance report
      uses: actions/upload-artifact@v4
      with:
        name: performance-report
        path: performance-report.md
        retention-days: 90

    - name: Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('performance-report.md', 'utf8');

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: `## 🚀 Performance Analysis Results\n\n${report}`
          });

  performance-alerting:
    name: Performance Alerting
    runs-on: ubuntu-latest
    needs: [frontend-performance, backend-performance, database-performance]
    if: failure()

    steps:
    - name: Send performance alert
      run: |
        echo "⚠️  Performance tests failed!"
        echo "Commit: ${{ github.sha }}"
        echo "Branch: ${{ github.ref_name }}"
        echo "Please review the performance test results and optimize accordingly."

        # Here you could integrate with Slack, email, or other alerting systems
        # Example:
        # curl -X POST -H 'Content-type: application/json' \
        #   --data '{"text":"Performance tests failed for commit ${{ github.sha }}"}' \
        #   ${{ secrets.SLACK_WEBHOOK_URL }}